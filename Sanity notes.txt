Sanity notes:

Hilbert value is a point on the hilbert curve. General idea is that similar tuples will be closer together on the hilbert curve. Use these points to draw bounding boxes that make up the r tree.

These points must first be sorted. Then, we can use the B+ tree bulk loading algorithm to insert these points without the need for heuristics and stuff.

Entries in a page = size of entries/size of page. Page should be stored on disk, but nothing too crazy.

Handling duplicates: read chapter 10.7 in textbook.

Now that I have the hilbert values in sorted order (ascending), we can bulk load the tree. One thing I need to find out: how many entries can fit in a 4K page? size of entries/4096=? What exactly was I given here? 

Important note: fanout is equal to the number of entries in a page. Unlike in B+ trees, where the fanout is 2d+1 (double the order + 1)

On indexing: do NOT index the hilbert value. Index both x and y values.

So: A leaf node is a box, not much to it. The parent node is the MBR of all the nodes contained in the parent. A non-leaf node will contain the dimensions of the rectangle (so, 4 ints). Non-leaf nodes can intersect. Class Rectangle should only act as a container, and it shouldn't know anything about what makes its dimensions. The bounding dimensions should be calculated in the main class. This could be changed later.

Calculating the order: size of entry + size of pointer <= 4096
=> size of entry*2d + size of pointer*2d <= 4096

Another problem: What exactly does an entry in a leaf node store? Intuition: the leaf node is a collection of points. The leaf node, therefore, can be consideedred an MBR for those points. This may be the last thing I need to implement bulk loading. 

Leaf node entries do not need to keep track of record IDs it seems, since we're using alternative 1.

Number of data points in a leaf node: 
2 ints = 8 bytes (x & y)
1 long = 8 bytes (should hilbert even be stored?)
500 character string = 500 bytes
total: 516 bytes
516*2d <= 4096
d <= 3.968992248
d = 3
Max d value: 6 = 2d

Number of indexes in a non-leaf node:
d<=204<=2d

How pages are stored on disk:
Have a page "ID", which starts at 0. This ID will be used as file names. In order to avoid parsing, I can utilize the Serializable class as the node is created. Note: I will not be making any updates to this database after it is created, so I will not need to write anything back.

Sanity check:
-Tuples are data points. They know nothing about their MBR.
-A node is a collection of rectangles (MBRs), leaf node or not. Calculations will change because of this...
-Where to store the MBR?
--Do we need a class "Entry"? Or should it be an interface, with there being two kinds to entries: data and index? Calculating the MBR for a data entry is different compared to finding the MBR for an index entry. 

Calculating the MBR for an index node:
We need access to the rectangles in the child node.

What to store in an index entry:
-The current MBR, but not an array of child rectangles

On duplicates: Use overflow pages it seems. Where should this reference go? In the tuple? YES! Tuple should contain a 4 byte reference to the next leaf node (which is the overflow page). This leaf node should only contain the tuples with duplicate keys.

Adding 1 reference to the Tuple class changes the calculation a bit:
2 ints = 8 bytes (x & y)
1 long = 8 bytes
500 char string = 500 bytes
1 reference to overflow page = 4 bytes
520*2d <= 4096
2d is still 7!
d is still 4!

back to dupicates: How are duplicates stored? Should unique keys only be stored at the leaf level, and any duplicates are stored in overflow pages? Or should we only be concerned about the last unique key entered in the leaf node, and create an overflow page once we run out of space? Opting for the former. Note: The tuple containing the reference to the overflow page also counts as an instance of the tuple!

Nice assumption we can make: there will never be a null element in the tuples array in between two non null elements. What this means: As soon as a null entry is found, we can safely insert the entry into the array without a care in the world. If we find a tuple with matching x and y values, this is a duplicate and we will need to create an overflow page for it.


Recursive part of bulk loading RTree:
-Create the leaf node and insert entries until limit is reached.
-Once leaf limit is reached, create entry in parent node.
-Once the index limit is reached in immediate parent node, don't split! Instead, create a new parent node and insert a new entry into this parent node (calculate MBR and stuff) and create a new child for the next leaf pages.
-Keep on creating children in this index node until it fills. Then go up one level and see if another child node can be made in that node.



New approach:

Create all leaf nodes (make sure to write them to disk before continuing on to the index nodes), and have an array of NodeReferences that corresponds to these leaf nodes. Now, start creating index nodes in the next level. Calculate MBR, and use NodeReference array to connect entries in index node to leaf nodes. Keep on creating these index nodes (make sure to write these to disk as well!) until the end of the NodeReference array is reached. While creating these index nodes, keep track of the NodeReferences in another array. So, the idea with indexing is to utilize the array of child nodes so we can connect the current level of nodes to their children, and to add NodeReferences to array so that the next level up can connect to the current level. Once the root node is reached, this means that the NodeReference array constructed in the previous iteration will fit in one node. If one node is created, then the bulk loading process is complete and the DB can be searched.




Searching: 
Maybe use recursion? 



Duplicates in the dataset: 
2655,3665
4156,3150
76,2308
718,9917
7747,5298
3660,4597
4930,4959
5782,3077
7107,106
926,5918
9338,1957










